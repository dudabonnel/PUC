{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulando Imagens\n",
    " `Prof. Dr. Rooney R. A. Coelho`\n",
    " \n",
    "* A classificação de imagens é uma das áreas mais interessantes do aprendizado de máquina. A capacidade dos computadores de reconhecer padrões e objetos a partir de imagens é uma ferramenta incrivelmente poderosa. \n",
    "* No entanto, antes de aplicarmos aprendizado de máquina às imagens, muitas vezes precisamos primeiro transformar as imagens brutas em recursos utilizáveis por nossos algoritmos de aprendizagem.\n",
    "* Para trabalhar com imagens, usaremos a Open Source Computer Vision Library (OpenCV). Embora existam uma série de boas bibliotecas por aí, o OpenCV é a biblioteca mais popular e documentada para lidar com imagens. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando Imagens\n",
    "\n",
    "Primeiramente vamos carregar uma imagem para pré-processamento\n",
    "- As imagens são dados binários que são convertidos para `numpy` usando o comando `imread`\n",
    "- Em escala de cinza temos uma matriz onde cada valor corresponde a uma intensidade (0-255)\n",
    "- O imwrite do OpenCV salva imagens do filepath especificado. O formato da imagem é definido pela extensão do nome do arquivo (.jpg, .png, etc.). \n",
    "- Um comportamento para ter cuidado é que o imwrite substituirá arquivos existentes sem produzir um erro ou pedir confirmação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('imagens/plane.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(image, cmap='gray') \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando a imagem\n",
    "cv2.imwrite('imagens/plane_new.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(image)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagens coloridas\n",
    "\n",
    "- Trabalhamos com três canais para representar uma imagem colorida\n",
    "- O OpenCV trabalha com a codificação BGR ao invés do RGB\n",
    "- Devemos inverter esses canais para visualizarmos uma imagem colorida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a imagem em cores\n",
    "image_bgr = cv2.imread('imagens/plane.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Mostrar um pixel\n",
    "image_bgr[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter para RGB\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "# Mostrar a imagem\n",
    "plt.imshow(image_rgb), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reescalando as imagens\n",
    "\n",
    "- Você quer redimensionar uma imagem para mais pré-processamento.\n",
    "- Redimensionar imagens é uma tarefa comum no pré-processamento de imagens por duas razões. \n",
    "    - Primeiro imagens vêm em todas as formas e tamanhos, e para ser utilizável como características, as imagens devem ter\n",
    "as mesmas dimensões. \n",
    "    - Essa padronização do tamanho da imagem vem com custos, imagens são matrizes de informação e quando reduzimos o tamanho da imagem\n",
    "estamos reduzindo o tamanho dessa matriz e as informações que ela contém. \n",
    "- Aprendizado de máquina pode exigir milhares ou centenas de milhares de imagens. Quando essas imagens são muito grandes eles podem tomar muita memória\n",
    "    - Redimensionando-as nós podemos reduzir drasticamente o uso da memória. \n",
    "- Alguns tamanhos de imagem comuns para máquina\n",
    "aprendendo são 32 × 32, 64 × 64, 96 × 96 e 256 × 256.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('imagens/plane_256x256.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "image_50x50 = cv2.resize(image, (50,50))\n",
    "\n",
    "plt.imshow(image_50x50, cmap='gray') \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recortando as imagens\n",
    "- Usamos quando Você deseja remover a parte externa da imagem para mudar suas dimensões.\n",
    "- Uma vez que o OpenCV representa imagens como uma matriz de elementos, selecionando as linhas e\n",
    "colunas que queremos manter somos capazes de cortar facilmente a imagem. \n",
    "- O corte pode ser particularmente útil se soubermos que só queremos manter uma certa parte de cada imagem.\n",
    "    - Por exemplo, se nossas imagens vêm de uma câmera de segurança estacionária, podemos cortar todas as imagens para que elas contenham apenas a área de interesse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('imagens/plane_256x256.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Seleciona a primeira metade das colunas e todas as linhas\n",
    "image_cropped = image[:,:128]\n",
    "\n",
    "plt.imshow(image_cropped, cmap='gray') \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desfocando as imagens\n",
    "\n",
    "- Para desfocar uma imagem, cada pixel é transformado para ser o valor médio de seus vizinhos.\n",
    "- Este vizinho e a operação realizada são matematicamente representados como um kernel. \n",
    "- O tamanho deste kernel determina a quantidade de desfoque, com núcleos maiores produzindo imagens mais suaves. \n",
    "    - Podemos aplicar manualmente um kernel a uma imagem usando filter2D para produzir um efeito de desfoque semelhante\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('imagens/plane_256x256.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Borrar a imagem\n",
    "image_blurry = cv2.blur(image, (5,5))\n",
    "\n",
    "plt.imshow(image_blurry, cmap='gray') \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aumentando a Nitidez\n",
    "\n",
    "- Você quer aumentar a nitidez de uma imagem.\n",
    "- Aumentar a nitidez funciona de forma semelhante ao desfoque, exceto que em vez de usar um kernel para obter a média dos valores vizinhos, construímos um kernel para destacar o pixel em si. \n",
    "- O efeito resultante faz com que contrastes nas bordas se destaquem mais na imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('imagens/plane_256x256.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Criar um kernel\n",
    "kernel = np.array([[0,-1,0],\n",
    "                   [-1,5,-1],\n",
    "                   [0,-1,0]])\n",
    "\n",
    "# Sharpen image\n",
    "image_sharp = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "plt.imshow(image_sharp, cmap='gray') \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aumentando o Contraste\n",
    "\n",
    "- Embora a imagem resultante muitas vezes não pareça \"realista\", precisamos lembrar que a imagem é apenas uma representação visual dos dados subjacentes. \n",
    "- Se a equalização do histograma é capaz de tornar objetos de interesse mais distinguíveis de outros objetos ou fundos (o que nem sempre é o caso), então pode ser uma adição valiosa ao nosso pipeline de pré-processamento de imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('imagens/plane_256x256.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Criar um kernel\n",
    "kernel = np.array([[0,-1,0],\n",
    "                   [-1,5,-1],\n",
    "                   [0,-1,0]])\n",
    "\n",
    "# Enhance image\n",
    "image_enhanced = cv2.equalizeHist(image)\n",
    "\n",
    "plt.imshow(image_enhanced, cmap='gray') \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a imagem\n",
    "image_bgr = cv2.imread('imagens/plane.jpg')\n",
    "# Converter para YUV\n",
    "image_yuv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2YUV)\n",
    "# Aplicar o hisograma de equalização\n",
    "image_yuv[:, :, 0] = cv2.equalizeHist(image_yuv[:, :, 0])\n",
    "# Converter para RGB\n",
    "image_rgb = cv2.cvtColor(image_yuv, cv2.COLOR_YUV2RGB)\n",
    "# Mostrar a imagem\n",
    "plt.imshow(image_rgb), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolando cores\n",
    "Isolar cores no OpenCV é simples. \n",
    "1. Primeiro convertemos uma imagem em HSV (matiz, saturação e valor). \n",
    "2. Em segundo lugar, definimos uma gama de valores que queremos isolar, que é provavelmente a parte mais difícil e demorada. \n",
    "3. Terceiro, criamos uma máscara para a imagem (só manteremos as áreas brancas):\n",
    "4. Finalmente, aplicamos a máscara à imagem usando bitwise_and e convertemos no formato de saída desejado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a imagem\n",
    "image_bgr = cv2.imread('imagens/plane_256x256.jpg')\n",
    "# Converter BGR para HSV\n",
    "image_hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)\n",
    "# Definir o range para azul em HSV\n",
    "lower_blue = np.array([50,100,50])\n",
    "upper_blue = np.array([130,255,255])\n",
    "# Criar uma máscara\n",
    "mask = cv2.inRange(image_hsv, lower_blue, upper_blue)\n",
    "# Mascarar a imagem\n",
    "image_bgr_masked = cv2.bitwise_and(image_bgr, image_bgr, mask=mask)\n",
    "# Converter de BGR para RGB\n",
    "image_rgb = cv2.cvtColor(image_bgr_masked, cv2.COLOR_BGR2RGB)\n",
    "# Mostrar a imagem\n",
    "plt.imshow(image_rgb), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar imagem\n",
    "plt.imshow(mask, cmap='gray'), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_rgb[:,:,0]\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarizando uma Imagem\n",
    "\n",
    "* Produzir uma versão simplificada.\n",
    "* Limiar é o processo de definição de pixels com intensidade maior que algum valor para ser branco e menor do que o valor para ser preto. \n",
    "* Uma técnica mais avançada é o limiar adaptativo, onde o valor limiar de um pixel é determinado pelas intensidades de pixels de seus vizinhos. \n",
    "    * Isso pode ser útil quando as condições de iluminação mudam sobre diferentes regiões em uma imagem\n",
    "* Um grande benefício do limiar é tirar o ruído de uma imagem — mantendo apenas o mais importante\n",
    "Elementos. \n",
    "    * Por exemplo, o limiar é frequentemente aplicado a fotos de texto impresso para isolar as letras da página.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar uma imagem em escala de cinza\n",
    "image_grey = cv2.imread('imagens/plane_256x256.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "# Aplicar limiar adaptativo\n",
    "max_output_value = 255\n",
    "neighborhood_size = 99\n",
    "subtract_from_mean = 10\n",
    "image_binarized = cv2.adaptiveThreshold(image_grey,\n",
    "                                        max_output_value,\n",
    "                                        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                        cv2.THRESH_BINARY,\n",
    "                                        neighborhood_size,\n",
    "                                        subtract_from_mean)\n",
    "# Mostrar imagem\n",
    "plt.imshow(image_binarized, cmap='gray'), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando cv2.ADAPTIVE_THRESH_MEAN_C\n",
    "image_mean_threshold = cv2.adaptiveThreshold(image_grey,\n",
    "                                            max_output_value,\n",
    "                                            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                            cv2.THRESH_BINARY,\n",
    "                                            neighborhood_size,\n",
    "                                            subtract_from_mean)\n",
    "# Mostrar a imagem\n",
    "plt.imshow(image_mean_threshold, cmap='gray'), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removendo o plano de fundo\n",
    "* Em nossa solução, começamos marcando um retângulo ao redor da área que contém o primeiro plano. \n",
    "* GrabCut assume que tudo fora deste retângulo é um fundo e usa essa informação para descobrir o que é provável de fundo dentro do quadrado\n",
    "* Em seguida, uma máscara é criada que denota as diferentes regiões de fundo/primeiro plano definitivamente/prováveis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a imagem e converter para RGB\n",
    "image_bgr = cv2.imread('imagens/plane_256x256.jpg')\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Valores do retângulo: start x, start y, width, height\n",
    "rectangle = (0, 56, 256, 150)\n",
    "\n",
    "# Criar uma máscara inicial\n",
    "mask = np.zeros(image_rgb.shape[:2], np.uint8)\n",
    "\n",
    "# Arrays temporários usados pelo grabCut\n",
    "bgdModel = np.zeros((1, 65), np.float64)\n",
    "fgdModel = np.zeros((1, 65), np.float64)\n",
    "\n",
    "# Rodar grabCut\n",
    "cv2.grabCut(image_rgb, # Imagem\n",
    "            mask, # Máscara\n",
    "            rectangle, # Retângulo\n",
    "            bgdModel, # Array temporário para o plano de fundo\n",
    "            fgdModel, # Array temporário para o plano de fundo\n",
    "            5, # Número de iterações\n",
    "            cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "# Criar uma máscara onde com certeza e prováveis planos de fundo são 0, caso contrário 1\n",
    "mask_2 = np.where((mask==2) | (mask==0), 0, 1).astype('uint8')\n",
    "\n",
    "# Multiplicar a imagem com a nova máscara para subtrair o plano de fundo\n",
    "image_rgb_nobg = image_rgb * mask_2[:, :, np.newaxis]\n",
    "\n",
    "# Mostrar imagem\n",
    "plt.imshow(image_rgb_nobg), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar a máscara\n",
    "plt.imshow(mask, cmap='gray'), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar a máscara\n",
    "plt.imshow(mask_2, cmap='gray'), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção de Bordas\n",
    "\n",
    "* A detecção de bordas é um dos principais tópicos de interesse na visão computacional. \n",
    "* As bordas são importantes porque são áreas de alta informação. \n",
    "    * Por exemplo, em nossa imagem um pedaço de céu se parece muito com o outro e é improvável que contenha informações únicas ou interessantes. \n",
    "* A detecção de bordas nos permite remover áreas de baixa informação e isolar as áreas de imagens que contêm mais informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image as grayscale\n",
    "image_gray = cv2.imread(\"imagens/plane_256x256.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "# Calculate median intensity\n",
    "median_intensity = np.median(image_gray)\n",
    "# Set thresholds to be one standard deviation above and below median intensity\n",
    "lower_threshold = int(max(0, (1.0 - 0.33) * median_intensity))\n",
    "upper_threshold = int(min(255, (1.0 + 0.33) * median_intensity))\n",
    "# Apply canny edge detector\n",
    "image_canny = cv2.Canny(image_gray, lower_threshold, upper_threshold)\n",
    "# Show image\n",
    "plt.imshow(image_canny, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção de cantos\n",
    "\n",
    "* O detector de canto Harris é um método comumente usado para detectar a intersecção de duas bordas. \n",
    "* Nosso interesse em detectar cantos é motivado pela mesma razão que as bordas: cantos são pontos de alta informação. \n",
    "* cornerHarris contém três parâmetros importantes que podemos usar para controlar as bordas detectadas. \n",
    "1. Primeiro, block_size é o tamanho do vizinho em torno de cada pixel usado para detecção de canto.\n",
    "2. Em segundo lugar, a abertura é o tamanho do kernel Sobel usado e, \n",
    "3. finalmente, há um parâmetro livre onde valores maiores correspondem à identificação de cantos mais suaves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar imagens em escala de cinza\n",
    "image_bgr = cv2.imread('imagens/plane_256x256.jpg')\n",
    "image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "image_gray = np.float32(image_gray)\n",
    "# Configuar os parâmetros do detector de quinas\n",
    "block_size = 2\n",
    "aperture = 29\n",
    "free_parameter = 0.04\n",
    "# Detectar as quinas\n",
    "detector_responses = cv2.cornerHarris(image_gray,\n",
    "                                    block_size,\n",
    "                                    aperture,\n",
    "                                    free_parameter)\n",
    "# Marcadores grandes para quinas \n",
    "detector_responses = cv2.dilate(detector_responses, None)\n",
    "\n",
    "# Mantém apenas as respostas para quinas maiores que o limiar e marcar de branco\n",
    "threshold = 0.02\n",
    "image_bgr[detector_responses > threshold * detector_responses.max()] = [255,255,255]\n",
    "# Converter para escala de cinza\n",
    "image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "# Mostrar imagem\n",
    "plt.imshow(image_gray, cmap='gray'), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar todas as prováveis quinas\n",
    "plt.imshow(detector_responses, cmap='gray'), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_gray == 255, cmap='gray'), plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar imagens\n",
    "image_bgr = cv2.imread('imagens/plane_256x256.jpg')\n",
    "image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "# Números de quinas para detectar\n",
    "corners_to_detect = 10\n",
    "minimum_quality_score = 0.05\n",
    "minimum_distance = 25\n",
    "\n",
    "# Detectar as quinas\n",
    "corners = cv2.goodFeaturesToTrack(image_gray,\n",
    "                                corners_to_detect,\n",
    "                                minimum_quality_score,\n",
    "                                minimum_distance).astype('int')\n",
    "\n",
    "# Desenhar um círculo branco em cada quina\n",
    "for i,corner in enumerate(corners):\n",
    "    x, y = corner[0]\n",
    "    print(f'Canto {i+1}: ({x},{y})')\n",
    "    cv2.circle(image_bgr,(x,y), 10, (255,255,255), -1)\n",
    "    cv2.putText(image_bgr, str(i+1), (x-2,y+1), cv2.FONT_HERSHEY_SIMPLEX, 0.25, (0,0,0), 1, cv2.LINE_AA)\n",
    "# Converter para escala de cinza\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "# Mostrar imagem\n",
    "plt.imshow(image_rgb, cmap='gray'), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando atributos para Aprendizagem de Máquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('imagens/plane_256x256.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Reescalar a imagem para 10x10 pixels\n",
    "image_10x10 = cv2.resize(image, (10, 10))\n",
    "print(image_10x10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_10x10, cmap='gray'), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a imagem para um vetor unidimensional\n",
    "image_10x10.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = image_10x10.flatten()\n",
    "\n",
    "plt.imshow(flattened.reshape((10,10)), cmap='gray'), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('imagens/plane_256x256.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Converter para RGB\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Reescalar a imagem para 10x10 pixels\n",
    "image_10x10 = cv2.resize(image, (10, 10))\n",
    "plt.imshow(image_10x10), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape( image_10x10 )\n",
    "#np.shape( image_10x10.flatten() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = image_10x10.flatten()\n",
    "\n",
    "plt.imshow(flattened.reshape((10,10,3))), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação de acordo com a cor média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a imagem em BGR\n",
    "image_bgr = cv2.imread(\"imagens/plane_256x256.jpg\", cv2.IMREAD_COLOR)\n",
    "# Calcular a média de cada canal\n",
    "channels = cv2.mean(image_bgr)\n",
    "# Inverter o Azul e o Vermelho (fazendo RGB ao invés de BGR)\n",
    "observation = np.array([(channels[2], channels[1], channels[0])])\n",
    "# Mostra a média de cada canal\n",
    "print(observation)\n",
    "\n",
    "plt.imshow(observation), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodificar o histograma de cores como atributos\n",
    "\n",
    "* Podemos calcular a frequência das cores na imagem\n",
    "* Cada canal pode conter um número entre 0 e 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar imagem\n",
    "image_bgr = cv2.imread(\"imagens/plane_256x256.jpg\", cv2.IMREAD_COLOR)\n",
    "# Converter para RGB\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "# Criar uma lista para o valor dos atributos\n",
    "features = []\n",
    "# Calcular o histograma para cada canal\n",
    "colors = ('r','g','b')\n",
    "# Para cada canal: calcular o histograma e adicionar à lista de features\n",
    "for i, channel in enumerate(colors):\n",
    "    histogram = cv2.calcHist([image_rgb], # Imagem\n",
    "                            [i], # Índice do canal\n",
    "                            None, # Sem usar máscara\n",
    "                            [256], # Tamanho do histograma\n",
    "                            [0,256]) # Range\n",
    "    plt.plot(histogram, color = channel)\n",
    "    plt.xlim([0,256])\n",
    "    features.append(histogram)\n",
    "plt.show()\n",
    "\n",
    "# Criar um vetor para as features (concatenação dos histogramas)\n",
    "observation = np.array(features).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(features).shape\n",
    "observation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste dos histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "images = [cv2.imread(file, cv2.IMREAD_COLOR) for file in glob.glob('imagens/histogramas/*.jpg')]\n",
    "\n",
    "n_fig = len(images)\n",
    "\n",
    "# Converter para RGB\n",
    "images_RGB = [cv2.cvtColor(image, cv2.COLOR_BGR2RGB) for image in images]\n",
    "\n",
    "# Escalonar para 256x256\n",
    "images_256x256 = [cv2.resize(image, (256, 256)) for image in images_RGB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Homem de Ferro',\n",
    "        'Máquina de Combate',\n",
    "        'Patriota de Ferro',\n",
    "        'Hulk Buster',\n",
    "        'Homem de Ferro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15)) # specifying the overall grid size\n",
    "\n",
    "for idx, image in enumerate(images_256x256):\n",
    "    plt.subplot(1, n_fig, idx+1)\n",
    "    plt.title(labels[idx])    \n",
    "    plt.imshow(image), plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprime_histograma(image):\n",
    "    # Remover o branco\n",
    "    mask = cv2.inRange(image, (255,255,255), (255,255,255))\n",
    "    mask = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Calcular o histograma para cada canal\n",
    "    colors = ('r','g','b')\n",
    "    # Para cada canal: calcular o histograma e adicionar à lista de features\n",
    "    for i, channel in enumerate(colors):\n",
    "        histogram = cv2.calcHist([image], # Imagem\n",
    "                                [i], # Índice do canal\n",
    "                                mask, # Máscara para o branco\n",
    "                                [256], # Tamanho do histograma\n",
    "                                [0,256]) # Range\n",
    "        plt.plot(histogram, color = channel)\n",
    "        plt.xlim([0,256])\n",
    "        plt.ylim([0,1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5)) # specifying the overall grid size\n",
    "\n",
    "idx = 0\n",
    "for image in images_256x256:\n",
    "    plt.subplot(2, n_fig, idx+1)\n",
    "    plt.title(labels[idx])\n",
    "    plt.imshow(image), plt.axis('off')\n",
    "    idx += 1\n",
    "\n",
    "for image in images_256x256:\n",
    "    plt.subplot(2, n_fig, idx+1)\n",
    "    imprime_histograma(image)    \n",
    "    idx += 1\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f396a9b3cf61373b3a1c29a6773edf0ca9449638ad9001937e504425ddafbde7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
